{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vidhya Analytics Case - BigMart Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "submit = pd.read_csv(\"Submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Item_Identifier Outlet_Identifier\n",
      "0           FDW58            OUT049\n",
      "1           FDW14            OUT017\n",
      "2           NCN55            OUT010\n",
      "3           FDQ58            OUT017\n",
      "4           FDY38            OUT027\n"
     ]
    }
   ],
   "source": [
    "print(submit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 12)\n",
      "(5681, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
      "0           FDA15         9.30          Low Fat         0.016047   \n",
      "1           DRC01         5.92          Regular         0.019278   \n",
      "2           FDN15        17.50          Low Fat         0.016760   \n",
      "3           FDX07        19.20          Regular         0.000000   \n",
      "4           NCD19         8.93          Low Fat         0.000000   \n",
      "\n",
      "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
      "0                  Dairy  249.8092            OUT049   \n",
      "1            Soft Drinks   48.2692            OUT018   \n",
      "2                   Meat  141.6180            OUT049   \n",
      "3  Fruits and Vegetables  182.0950            OUT010   \n",
      "4              Household   53.8614            OUT013   \n",
      "\n",
      "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
      "0                       1999      Medium               Tier 1   \n",
      "1                       2009      Medium               Tier 3   \n",
      "2                       1999      Medium               Tier 1   \n",
      "3                       1998         NaN               Tier 3   \n",
      "4                       1987        High               Tier 3   \n",
      "\n",
      "         Outlet_Type  Item_Outlet_Sales  \n",
      "0  Supermarket Type1          3735.1380  \n",
      "1  Supermarket Type2           443.4228  \n",
      "2  Supermarket Type1          2097.2700  \n",
      "3      Grocery Store           732.3800  \n",
      "4  Supermarket Type1           994.7052   \n",
      "============================================================\n",
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility    Item_Type  \\\n",
      "0           FDW58       20.750          Low Fat         0.007565  Snack Foods   \n",
      "1           FDW14        8.300              reg         0.038428        Dairy   \n",
      "2           NCN55       14.600          Low Fat         0.099575       Others   \n",
      "3           FDQ58        7.315          Low Fat         0.015388  Snack Foods   \n",
      "4           FDY38          NaN          Regular         0.118599        Dairy   \n",
      "\n",
      "   Item_MRP Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
      "0  107.8622            OUT049                       1999      Medium   \n",
      "1   87.3198            OUT017                       2007         NaN   \n",
      "2  241.7538            OUT010                       1998         NaN   \n",
      "3  155.0340            OUT017                       2007         NaN   \n",
      "4  234.2300            OUT027                       1985      Medium   \n",
      "\n",
      "  Outlet_Location_Type        Outlet_Type  \n",
      "0               Tier 1  Supermarket Type1  \n",
      "1               Tier 2  Supermarket Type1  \n",
      "2               Tier 3      Grocery Store  \n",
      "3               Tier 2  Supermarket Type1  \n",
      "4               Tier 3  Supermarket Type3  \n"
     ]
    }
   ],
   "source": [
    "print(train.head(),'\\n============================================================')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.857645</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>140.992782</td>\n",
       "      <td>1997.831867</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.643456</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>62.275067</td>\n",
       "      <td>8.371760</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.773750</td>\n",
       "      <td>0.026989</td>\n",
       "      <td>93.826500</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>143.012800</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.850000</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>185.643700</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  7060.000000      8523.000000  8523.000000                8523.000000   \n",
       "mean     12.857645         0.066132   140.992782                1997.831867   \n",
       "std       4.643456         0.051598    62.275067                   8.371760   \n",
       "min       4.555000         0.000000    31.290000                1985.000000   \n",
       "25%       8.773750         0.026989    93.826500                1987.000000   \n",
       "50%      12.600000         0.053931   143.012800                1999.000000   \n",
       "75%      16.850000         0.094585   185.643700                2004.000000   \n",
       "max      21.350000         0.328391   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     count unique                    top  freq\n",
      "Item_Identifier       8523   1559                  FDW13    10\n",
      "Item_Fat_Content      8523      5                Low Fat  5089\n",
      "Item_Type             8523     16  Fruits and Vegetables  1232\n",
      "Outlet_Identifier     8523     10                 OUT027   935\n",
      "Outlet_Size           6113      3                 Medium  2793\n",
      "Outlet_Location_Type  8523      3                 Tier 3  3350\n",
      "Outlet_Type           8523      4      Supermarket Type1  5577\n"
     ]
    }
   ],
   "source": [
    "print(train.describe(include = 'object').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Fat    5517\n",
      "Regular    3006\n",
      "Name: Item_Fat_Content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replacing values in 'Item_Fat_Content' variable :\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print(train['Item_Fat_Content'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Fat    3668\n",
      "Regular    2013\n",
      "Name: Item_Fat_Content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print(test['Item_Fat_Content'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food              6125\n",
       "Non-Consumable    1599\n",
       "Drinks             799\n",
       "Name: Item_Type_Combined, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the first two characters of ID:\n",
    "train['Item_Type_Combined'] = train['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "#Rename them to more intuitive categories:\n",
    "train['Item_Type_Combined'] = train['Item_Type_Combined'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'}) \n",
    "train['Item_Type_Combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food              4076\n",
       "Non-Consumable    1087\n",
       "Drinks             518\n",
       "Name: Item_Type_Combined, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the first two characters of ID:\n",
    "test['Item_Type_Combined'] = test['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "#Rename them to more intuitive categories:\n",
    "test['Item_Type_Combined'] = test['Item_Type_Combined'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'}) \n",
    "test['Item_Type_Combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new variable total years from Outlet_Establishment_Year\n",
    "train['total_years']= 2020 - train['Outlet_Establishment_Year']\n",
    "test['total_years']= 2020 - train['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Item_Identifier','Outlet_Establishment_Year'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['Item_Identifier','Outlet_Establishment_Year'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Item_Weight  Item_Visibility     Item_MRP  Item_Outlet_Sales  \\\n",
      "count  7060.000000      8523.000000  8523.000000        8523.000000   \n",
      "mean     12.857645         0.066132   140.992782        2181.288914   \n",
      "std       4.643456         0.051598    62.275067        1706.499616   \n",
      "min       4.555000         0.000000    31.290000          33.290000   \n",
      "25%       8.773750         0.026989    93.826500         834.247400   \n",
      "50%      12.600000         0.053931   143.012800        1794.331000   \n",
      "75%      16.850000         0.094585   185.643700        3101.296400   \n",
      "max      21.350000         0.328391   266.888400       13086.964800   \n",
      "\n",
      "       total_years  \n",
      "count  8523.000000  \n",
      "mean     22.168133  \n",
      "std       8.371760  \n",
      "min      11.000000  \n",
      "25%      16.000000  \n",
      "50%      21.000000  \n",
      "75%      33.000000  \n",
      "max      35.000000  \n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     count unique                    top  freq\n",
      "Item_Fat_Content      8523      2                Low Fat  5517\n",
      "Item_Type             8523     16  Fruits and Vegetables  1232\n",
      "Outlet_Identifier     8523     10                 OUT027   935\n",
      "Outlet_Size           6113      3                 Medium  2793\n",
      "Outlet_Location_Type  8523      3                 Tier 3  3350\n",
      "Outlet_Type           8523      4      Supermarket Type1  5577\n",
      "Item_Type_Combined    8523      3                   Food  6125\n"
     ]
    }
   ],
   "source": [
    "print(train.describe(include = 'object').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for other data metrics - skewness, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness before transformation \n",
      "  Item_Weight          0.082426\n",
      "Item_Visibility      1.167091\n",
      "Item_MRP             0.127202\n",
      "Item_Outlet_Sales    1.177531\n",
      "total_years          0.396641\n",
      "dtype: float64\n",
      "Skewness of target variable \n",
      "  1.1775306028542798\n",
      "skewness after log \n",
      " -0.887753343209305\n",
      "skewness after sqrt \n",
      " 0.23467599347099247\n",
      "skewness after boxcox \n",
      "  -0.0749780634829317\n",
      "0    3735.1380\n",
      "1     443.4228\n",
      "2    2097.2700\n",
      "3     732.3800\n",
      "4     994.7052\n",
      "Name: Item_Outlet_Sales, dtype: float64\n",
      "[3704.29144842  441.05298554 2081.6421515  ... 1185.15075816 1832.17223952\n",
      "  761.02086604]\n"
     ]
    }
   ],
   "source": [
    "print(\"skewness before transformation \\n \",train.skew(axis = 0, skipna = True))\n",
    "print(\"Skewness of target variable \\n \",train['Item_Outlet_Sales'].skew())\n",
    "# applying log on target variable     \n",
    "log_y = np.log(train['Item_Outlet_Sales'])\n",
    "print(\"skewness after log \\n\",log_y.skew())\n",
    "# applying sqrt on target variable\n",
    "sqrt_y = np.sqrt(train['Item_Outlet_Sales'])\n",
    "print(\"skewness after sqrt \\n\",sqrt_y.skew())\n",
    "#applying boxcox on target variable\n",
    "boxcox_y = stats.boxcox(train['Item_Outlet_Sales'])[0]\n",
    "print(\"skewness after boxcox \\n \",pd.Series(boxcox_y).skew())\n",
    "print(train['Item_Outlet_Sales'].head())\n",
    "print(inv_boxcox(boxcox_y,.347))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>total_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014048</td>\n",
       "      <td>0.027141</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.011588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>-0.014048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.128625</td>\n",
       "      <td>0.074834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0.027141</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.567574</td>\n",
       "      <td>-0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <td>0.014123</td>\n",
       "      <td>-0.128625</td>\n",
       "      <td>0.567574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_years</th>\n",
       "      <td>0.011588</td>\n",
       "      <td>0.074834</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item_Weight  Item_Visibility  Item_MRP  Item_Outlet_Sales  \\\n",
       "Item_Weight           1.000000        -0.014048  0.027141           0.014123   \n",
       "Item_Visibility      -0.014048         1.000000 -0.001315          -0.128625   \n",
       "Item_MRP              0.027141        -0.001315  1.000000           0.567574   \n",
       "Item_Outlet_Sales     0.014123        -0.128625  0.567574           1.000000   \n",
       "total_years           0.011588         0.074834 -0.005020           0.049135   \n",
       "\n",
       "                   total_years  \n",
       "Item_Weight           0.011588  \n",
       "Item_Visibility       0.074834  \n",
       "Item_MRP             -0.005020  \n",
       "Item_Outlet_Sales     0.049135  \n",
       "total_years           1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train-test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Item_Outlet_Sales']\n",
    "X= train.drop(['Item_Outlet_Sales'], axis=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20,random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "\n",
    "print(type(X_valid))\n",
    "print(type(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Catogorical and Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr = list(train.select_dtypes(\"object\").columns)\n",
    "num_attr = list(train.columns.difference(cat_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Fat_Content',\n",
       " 'Item_Type',\n",
       " 'Outlet_Identifier',\n",
       " 'Outlet_Size',\n",
       " 'Outlet_Location_Type',\n",
       " 'Outlet_Type',\n",
       " 'Item_Type_Combined']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item_MRP', 'Item_Outlet_Sales', 'Item_Visibility', 'Item_Weight', 'total_years']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Item_MRP', 'Item_Visibility', 'Item_Weight', 'total_years']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(num_attr)\n",
    "num_attr.pop(1)\n",
    "num_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train = X_train[cat_attr]\n",
    "df_cat_val = X_valid[cat_attr]\n",
    "df_num_train = X_train[num_attr]\n",
    "df_num_val = X_valid[num_attr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = test[cat_attr]\n",
    "test_num = test[num_attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Item_Fat_Content           Item_Type Outlet_Identifier Outlet_Size  \\\n",
      "6926          Regular         Snack Foods            OUT019       Small   \n",
      "5168          Low Fat  Health and Hygiene            OUT049      Medium   \n",
      "\n",
      "     Outlet_Location_Type        Outlet_Type Item_Type_Combined  \n",
      "6926               Tier 1      Grocery Store               Food  \n",
      "5168               Tier 1  Supermarket Type1     Non-Consumable  \n",
      "      Item_MRP  Item_Visibility  Item_Weight  total_years\n",
      "6926   86.8514         0.216108          NaN           35\n",
      "5168   33.3874         0.055076         13.5           21\n",
      "   Item_MRP  Item_Visibility  Item_Weight  total_years\n",
      "0  107.8622         0.007565        20.75           21\n",
      "1   87.3198         0.038428         8.30           11\n",
      "  Item_Fat_Content    Item_Type Outlet_Identifier Outlet_Size  \\\n",
      "0          Low Fat  Snack Foods            OUT049      Medium   \n",
      "1          Regular        Dairy            OUT017         NaN   \n",
      "\n",
      "  Outlet_Location_Type        Outlet_Type Item_Type_Combined  \n",
      "0               Tier 1  Supermarket Type1               Food  \n",
      "1               Tier 2  Supermarket Type1               Food  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat_train.head(2))\n",
    "print(df_num_train.head(2))\n",
    "print(test_num.head(2))\n",
    "print(test_cat.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Weight             1463\n",
      "Item_Fat_Content           0\n",
      "Item_Visibility            0\n",
      "Item_Type                  0\n",
      "Item_MRP                   0\n",
      "Outlet_Identifier          0\n",
      "Outlet_Size             2410\n",
      "Outlet_Location_Type       0\n",
      "Outlet_Type                0\n",
      "Item_Outlet_Sales          0\n",
      "Item_Type_Combined         0\n",
      "total_years                0\n",
      "dtype: int64\n",
      "Item_Weight              976\n",
      "Item_Fat_Content           0\n",
      "Item_Visibility            0\n",
      "Item_Type                  0\n",
      "Item_MRP                   0\n",
      "Outlet_Identifier          0\n",
      "Outlet_Size             1606\n",
      "Outlet_Location_Type       0\n",
      "Outlet_Type                0\n",
      "Item_Type_Combined         0\n",
      "total_years                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_size = train.groupby(['Item_Outlet_Sales','Outlet_Size']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    2793\n",
       "Small     2388\n",
       "High       932\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    1862\n",
       "Small     1592\n",
       "High       621\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing Missing Values using Mode and Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute on train\n",
    "df_cat_train = df_cat_train.fillna(df_cat_train.mode().iloc[0])\n",
    "\n",
    "# Impute on test\n",
    "df_cat_val = df_cat_val.fillna(df_cat_val.mode().iloc[0])\n",
    "\n",
    "# test\n",
    "test_cat = test_cat.fillna(test_cat.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute on train\n",
    "df_num_train = df_num_train.fillna(df_num_train.mean())\n",
    "\n",
    "#Impute on val\n",
    "df_num_val = df_num_val.fillna(df_num_val.mean())\n",
    "\n",
    "# Impute on test\n",
    "test_num = test_num.fillna(test_num.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Numerical and Categorical variables post imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numeric and categorical in train\n",
    "X_train = pd.concat([df_num_train, df_cat_train], axis = 1)\n",
    "\n",
    "# Combine numeric and categorical val\n",
    "X_valid = pd.concat([df_num_val, df_cat_val], axis = 1)\n",
    "\n",
    "# Combine numeric and categorical in test\n",
    "test = pd.concat([test_num, test_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6818, 11)\n",
      "(5681, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Categorical to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical Columns to Dummies\n",
    "# Train\n",
    "X_train = pd.get_dummies(X_train, columns=cat_attr, drop_first=True)\n",
    "\n",
    "# valid\n",
    "X_valid = pd.get_dummies(X_valid, columns=cat_attr, drop_first=True)\n",
    "\n",
    "# test\n",
    "test = pd.get_dummies(test, columns=cat_attr, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_MRP', 'Item_Visibility', 'Item_Weight', 'total_years',\n",
       "       'Item_Fat_Content_Regular', 'Item_Type_Breads', 'Item_Type_Breakfast',\n",
       "       'Item_Type_Canned', 'Item_Type_Dairy', 'Item_Type_Frozen Foods',\n",
       "       'Item_Type_Fruits and Vegetables', 'Item_Type_Hard Drinks',\n",
       "       'Item_Type_Health and Hygiene', 'Item_Type_Household', 'Item_Type_Meat',\n",
       "       'Item_Type_Others', 'Item_Type_Seafood', 'Item_Type_Snack Foods',\n",
       "       'Item_Type_Soft Drinks', 'Item_Type_Starchy Foods',\n",
       "       'Outlet_Identifier_OUT013', 'Outlet_Identifier_OUT017',\n",
       "       'Outlet_Identifier_OUT018', 'Outlet_Identifier_OUT019',\n",
       "       'Outlet_Identifier_OUT027', 'Outlet_Identifier_OUT035',\n",
       "       'Outlet_Identifier_OUT045', 'Outlet_Identifier_OUT046',\n",
       "       'Outlet_Identifier_OUT049', 'Outlet_Size_Medium', 'Outlet_Size_Small',\n",
       "       'Outlet_Location_Type_Tier 2', 'Outlet_Location_Type_Tier 3',\n",
       "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Supermarket Type2',\n",
       "       'Outlet_Type_Supermarket Type3', 'Item_Type_Combined_Food',\n",
       "       'Item_Type_Combined_Non-Consumable'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train.loc[:,num_attr])\n",
    "\n",
    "# scale on train\n",
    "X_train.loc[:,num_attr] = scaler.transform(X_train.loc[:,num_attr])\n",
    "\n",
    "# scale on valid\n",
    "X_valid.loc[:,num_attr] = scaler.transform(X_valid.loc[:,num_attr])\n",
    "\n",
    "# scale on test\n",
    "test.loc[:,num_attr] = scaler.transform(test.loc[:,num_attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building-1: Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663.4388092666932\n",
      "1636.5855772049254\n"
     ]
    }
   ],
   "source": [
    "svr = SVR() \n",
    "svr.fit(X_train,y_train)\n",
    "svr_train_pred = svr.predict(X_train)\n",
    "svr_valid_pred = svr.predict(X_valid)\n",
    "svr_test_pred = svr.predict(test)\n",
    "print(np.sqrt(mean_squared_error(y_train, svr_train_pred)))\n",
    "#print(MAPE(y_valid, linear_reg_valid_pred))\n",
    "print(np.sqrt(mean_squared_error(y_valid, svr_valid_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svr = pd.DataFrame(svr_test_pred)\n",
    "#sub = pd.concat([test_data['id'],test_predict],axis=1)\n",
    "sub = pd.concat([submit,test_pred_svr],axis = 1)\n",
    "sub.to_csv('svr_reg.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svr with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1.5, 10], 'epsilon': [0.1, 0.2, 0.5, 0.3],\n",
       "                         'gamma': [1e-07, 0.0001], 'kernel': ('rbf', 'poly')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel': ('rbf','poly'), \n",
    "              'C':[1.5, 10],'gamma': [1e-7, 1e-4],\n",
    "              'epsilon':[0.1,0.2,0.5,0.3]}\n",
    "svr_gs = GridSearchCV(svr, parameters)\n",
    "svr_gs.fit(X_train,y_train)                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'epsilon': 0.2, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "best_param = svr_gs.best_params_\n",
    "print(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746.6520874766265\n",
      "1719.2329504819056\n"
     ]
    }
   ],
   "source": [
    "svr_best= SVR(**best_param)\n",
    "svr_best.fit(X_train,y_train)\n",
    "svr_best_train_pred = svr_best.predict(X_train)\n",
    "svr_best_valid_pred = svr_best.predict(X_valid)\n",
    "svr_best_test_pred = svr_best.predict(test)\n",
    "print(np.sqrt(mean_squared_error(y_train, svr_best_train_pred)))\n",
    "#print(MAPE(y_valid, linear_reg_valid_pred))\n",
    "print(np.sqrt(mean_squared_error(y_valid, svr_best_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svr_best = pd.DataFrame(svr_best_test_pred)\n",
    "\n",
    "#sub = pd.concat([test_data['id'],test_predict],axis=1)\n",
    "sub = pd.concat([submit,test_pred_svr_best],axis = 1)\n",
    "sub.to_csv('svr_best.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building-2: Tranformed Target Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141.704394759487\n",
      "1132.5105354906877\n"
     ]
    }
   ],
   "source": [
    "regr_trans = TransformedTargetRegressor(regressor=LinearRegression(),\n",
    "                                        func=np.log1p,\n",
    "                                        inverse_func=np.expm1)\n",
    "regr_trans.fit(X_train, y_train)\n",
    "regr_trans_train_pred = regr_trans.predict(X_train)\n",
    "regr_trans_valid_pred = regr_trans.predict(X_valid)\n",
    "regr_trans_test_pred = regr_trans.predict(test)\n",
    "print(np.sqrt(mean_squared_error(y_train, regr_trans_train_pred)))\n",
    "#print(MAPE(y_valid, linear_reg_valid_pred))\n",
    "print(np.sqrt(mean_squared_error(y_valid, regr_trans_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(regr_trans_test_pred)\n",
    "\n",
    "#sub = pd.concat([test_data['id'],test_predict],axis=1)\n",
    "sub = pd.concat([submit,test_pred],axis = 1)\n",
    "sub.to_csv('regr_trans.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_train = stats.boxcox(y_train)[0]\n",
    "boxcox_valid = stats.boxcox(y_valid)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:31] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "6.384702521441244\n",
      "6.339024758938015\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf =XGBRegressor(**params)\n",
    "\n",
    "clf.fit(X_train, boxcox_train)\n",
    "train_pred_xg = clf.predict(X_train)\n",
    "val_pred_xg = clf.predict(X_valid)\n",
    "test_pred_xg = clf.predict(test)\n",
    "print(np.sqrt(mean_squared_error(boxcox_train, train_pred_xg)))\n",
    "print(np.sqrt(mean_squared_error(boxcox_valid, val_pred_xg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083.2663822198476\n",
      "954.9596250766928\n"
     ]
    }
   ],
   "source": [
    "# inersing boxcox \n",
    "train_pred_xg = inv_boxcox(train_pred_xg,.347)\n",
    "y_train_inv = inv_boxcox(boxcox_train,.347)\n",
    "print(np.sqrt(mean_squared_error(y_train_inv, train_pred_xg)))\n",
    "\n",
    "val_pred_xg = inv_boxcox(val_pred_xg,.347)\n",
    "y_val_inv = inv_boxcox(boxcox_valid,.347)\n",
    "print(np.sqrt(mean_squared_error(y_val_inv, val_pred_xg)))\n",
    "\n",
    "test_pred_xg = inv_boxcox(test_pred_xg,.347)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(test_pred_xg)\n",
    "\n",
    "#sub = pd.concat([test_data['id'],test_predict],axis=1)\n",
    "sub = pd.concat([submit,test_pred],axis = 1)\n",
    "sub.to_csv('xgb_best.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
